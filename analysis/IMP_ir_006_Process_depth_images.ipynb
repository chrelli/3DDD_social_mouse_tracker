{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, now make a function to process images, collapse to a pointcloud and dump to an h5py file\n",
    "\n",
    "%matplotlib qt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys, os, pickle\n",
    "import cv2\n",
    "from colour import Color\n",
    "import h5py\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import glob\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the timing and geometry, load depth images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['start_frame', 'end_frame', 'd_cam_params', 'c_cam_params', 'R_extrinsics', 't_extrinsics', 'R_world', 't_world', 'M0', 'floor_point', 'floor_normal', 'c_cylinder', 'r_cylinder'])\n",
      "dict_keys(['master_frame_table', 'reference_time_cam', 'reference_stamps', 'time_stamps', 'shifted_stamps'])\n"
     ]
    }
   ],
   "source": [
    "# load the geometry\n",
    "\n",
    "top_folder_0 = '/media/chrelli/Data0/recording_20200821-131033'\n",
    "top_folder_1 = '/media/chrelli/Data1/recording_20200821-131033'\n",
    "\n",
    "top_folder_0 = '/media/chrelli/Data0/recording_20200828-111528'\n",
    "top_folder_1 = '/media/chrelli/Data1/recording_20200828-111528'\n",
    "\n",
    "# validation dataset with LASER ON 90 fps\n",
    "top_folder_0 = '/media/chrelli/Data0/recording_20200828-114251'\n",
    "top_folder_1 = '/media/chrelli/Data1/recording_20200828-114251'\n",
    "# training data with implant \n",
    "top_folder_0 = '/media/chrelli/Data0/recording_20201107-092409/'\n",
    "top_folder_1 = '/media/chrelli/Data1/recording_20201107-092409/'\n",
    "\n",
    "\n",
    "# DAta with male partner\n",
    "top_folder_0 = '/media/chrelli/Data0/recording_20201109-113010'\n",
    "top_folder_1 = '/media/chrelli/Data1/recording_20201109-113010'\n",
    "\n",
    "# Data with female partner 3500 exposure\n",
    "top_folder_0 = '/media/chrelli/Data0/recording_20201110-102009/'\n",
    "top_folder_1 = '/media/chrelli/Data1/recording_20201110-102009/'\n",
    "\n",
    "# Data with male partner 3500 exposure\n",
    "top_folder_0 = '/media/chrelli/SSD4TB/Data0_backup/recording_20201110-105540'\n",
    "top_folder_1 = '/media/chrelli/SSD4TB/Data1_backup/recording_20201110-105540'\n",
    "\n",
    "# # Thrusting data\n",
    "# top_folder_0 = '/media/chrelli/Data0/recording_20201112-104816/'\n",
    "# top_folder_1 = '/media/chrelli/Data1/recording_20201112-104816/'\n",
    "\n",
    "\n",
    "scene_folders = [top_folder_0,top_folder_0,top_folder_1,top_folder_1]\n",
    "import pickle\n",
    "geometry = pickle.load( open( scene_folders[0]+'/geometry.pkl', \"rb\" ) ) \n",
    "timing = pickle.load( open( scene_folders[0]+'/timing.pkl', \"rb\" ) )\n",
    "print(geometry.keys())\n",
    "print(timing.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also make a list of all the frames to process\n",
    "# make a list of the cameras!\n",
    "d_files = [glob.glob(scene_folders[i] + '/npy_raw/dev' +str(i) +'_d_*.png') for i in range(4)]\n",
    "d_files = [sorted(f) for f in d_files]\n",
    "\n",
    "png_files = [glob.glob(scene_folders[i] + '/npy_raw/dev' +str(i) +'_ir_*.png') for i in range(4)]\n",
    "png_files = [sorted(f) for f in png_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['dataset']>\n",
      "59537\n",
      "[ 66  95  71  72  67  74  76  70  46 122  70 103  65 112  31 116  99  65\n",
      "  22  16  11   0   1   1   2   3   3   3]\n",
      "<KeysViewHDF5 ['dataset']>\n",
      "59364\n",
      "[ 71  56  70  51  76  60  78  39 113  71  92  13   1   1   2   3]\n",
      "<KeysViewHDF5 ['dataset']>\n",
      "59368\n",
      "[ 52  76  49  70  51  72  51  80  56  73  52  80  54  62 101  52  49  38\n",
      "  59  18  68   1   1   1   1   2   2   3]\n",
      "<KeysViewHDF5 ['dataset']>\n",
      "59369\n",
      "[ 62  90  65  87  67 102 120  90  11   1   2   3]\n"
     ]
    }
   ],
   "source": [
    "# load all the keypoint data (since it's so tiny!)\n",
    "# OK, try to see if the data is in the h5py file\n",
    "keyp_datasets = []\n",
    "for dev in range(4):\n",
    "    with h5py.File(top_folder_0+'/keypoints_'+str(dev)+'.hdf5', mode='r') as hdf5_file:\n",
    "        print(hdf5_file.keys())\n",
    "        print(len(hdf5_file['dataset']))\n",
    "        print( hdf5_file['dataset'][500] )\n",
    "        keyp_datasets.append(hdf5_file['dataset'][...])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a function to align depth to color images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_d_to_c(d_image,c_image,dev,geometry):\n",
    "    # todo can be sped up    \n",
    "    pi,pj = np.where( (d_image>0) ) # simply all\n",
    "    dij = d_image[pi,pj]\n",
    "\n",
    "    fx,fy,ppx,ppy,depth_scale,fps,frame_width,frame_height = geometry['d_cam_params'][dev]\n",
    "    fps,frame_width,frame_height = fps.astype('int'),frame_width.astype('int'),frame_height.astype('int')\n",
    "    fx_c,fy_c,ppx_c,ppy_c,_,_,frame_width_c,frame_height_c = geometry['c_cam_params'][dev]\n",
    "    \n",
    "    frame_width_c,frame_height_c = int(frame_width_c),int(frame_height_c)\n",
    "    \n",
    "    # FIX the geometry due to downsample\n",
    "    # the depth image is downsampled\n",
    "    fx,fy,ppx,ppy = fx/2,fy/2,ppx/2,ppy/2\n",
    "    frame_width,frame_height = int(frame_width/2),int(frame_height/2)\n",
    "\n",
    "    \n",
    "    z_m = dij*depth_scale # +1e-6\n",
    "\n",
    "    # and now use pinhole cam function to get the x and y\n",
    "    x_m = (pj - ppx) * z_m / fx\n",
    "    y_m = (pi - ppy) * z_m / fy    \n",
    "\n",
    "    # and pack to a stack of positions!\n",
    "    positions_depth_space = np.vstack((x_m,y_m,z_m)).T    \n",
    "\n",
    "    # swing the depth positions to the color space\n",
    "    R_extr = geometry['R_extrinsics'][dev]\n",
    "    t_extr = geometry['t_extrinsics'][dev]\n",
    "    positions_color_space = np.einsum('ij,aj->ai',R_extr,positions_depth_space) + t_extr\n",
    "\n",
    "    # now we can caculate cu and cj, the index in the color frame of each point\n",
    "    ci = np.round(positions_color_space[:,1] * fy_c / positions_color_space[:,2] + ppy_c)\n",
    "    cj = np.round(positions_color_space[:,0] * fx_c / positions_color_space[:,2] + ppx_c)\n",
    "\n",
    "    # make sure that they are good (actually, should probably set to zero outside)\n",
    "    ci = np.clip(ci,0,frame_height_c-1).astype(int)\n",
    "    cj = np.clip(cj,0,frame_width_c-1).astype(int)    \n",
    "\n",
    "    # depth aligned to color\n",
    "    \n",
    "    dac_image = np.zeros((frame_height_c,frame_width_c))\n",
    "    dac_mask = np.zeros((frame_height_c,frame_width_c))\n",
    "    # return the depth in meters\n",
    "    dac_image[ci,cj] = dij\n",
    "    dac_mask[ci,cj] = 1\n",
    "    sigma_g = 3\n",
    "    # dac_image = cv2.medianBlur(dac_image.astype('uint16'),5)\n",
    "    # dac_image = cv2.GaussianBlur(dac_image,(sigma_g,sigma_g),0)/cv2.GaussianBlur(dac_mask,(sigma_g,sigma_g),0)\n",
    "    # dac_image = dac_image[:,:,0]/dac_image[:,:,1]\n",
    "    return dac_image.astype('uint16')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions to align, merge and cut the pointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "#%% also set up the cylinder filtering!\n",
    "c_cylinder = geometry['c_cylinder']\n",
    "r_cylinder = geometry['r_cylinder']\n",
    "floor_point = geometry['floor_point']\n",
    "floor_normal = geometry['floor_normal']\n",
    "M0 = geometry['M0']\n",
    "\n",
    "def apply_rigid_transformation(positions,R,t):\n",
    "    # takes postions as a Nx3 vector and applies rigid transformation\n",
    "    # make matrices\n",
    "    A = np.asmatrix(positions)\n",
    "    R = np.asmatrix(R)\n",
    "    t = np.asmatrix(t).T\n",
    "\n",
    "    # Matrix way:\n",
    "    n = A.shape[0]\n",
    "    A2 = np.matmul(R,A.T) + np.tile(t, (1, n))\n",
    "\n",
    "    # print(str(i)+' after transform: '+str(A2.shape))\n",
    "    # make it an array?\n",
    "    return np.asarray(A2.T)\n",
    "\n",
    "\n",
    "def cut_by_floor_roof(positions,floor_point,floor_normal,floor_cut=0.005,roof_cut=0.01):\n",
    "    \"\"\"\n",
    "    Function to cut away the floor w/o a need to rotate the points fikst, just use the dot product trick\n",
    "    # cut away floor?\n",
    "    # use the equation of the plane: http://tutorial.math.lamar.edu/Classes/CalcIII/EqnsOfPlanes.aspx\n",
    "    # and evaluate this to check if it's above or below: https://stackoverflow.com/questions/15688232/check-which-side-of-a-plane-points-are-on\n",
    "\n",
    "    \"\"\"\n",
    "    # find the first coefficients of the equation of the plane!\n",
    "    plane_coeffs = floor_normal\n",
    "\n",
    "        # find a point above the plane!\n",
    "    hover_point = floor_point + floor_normal * floor_cut\n",
    "    roof_point = floor_point + floor_normal * roof_cut\n",
    "        # calculate d, which is the dot product between a point on the plane and the normal\n",
    "    floor_d = np.dot(floor_normal,hover_point)\n",
    "    roof_d = np.dot(floor_normal,roof_point)\n",
    "\n",
    "    # the idea is to calc ax+by+cz+d where abc is the normal and xyz is the point being tested\n",
    "    # now do the dot product as the logic to pflip on the sign (don't care about equal to)\n",
    "    #test_prod = np.dot(positions,plane_coeffs[0:3])\n",
    "    # einsum is faster!\n",
    "    test_prod = np.einsum('j,ij->i',plane_coeffs,positions)\n",
    "\n",
    "\n",
    "    above_logic = (test_prod > floor_d) * (test_prod < roof_d)\n",
    "    return above_logic\n",
    "\n",
    "\n",
    "def align_by_floor(positions,floor_point,M0):\n",
    "    positions = positions - floor_point\n",
    "    # rotate!\n",
    "    #TODO desperate need to convert everything to 4D transformations!! Here translation is first, then rotate. Above it's the other way around Yikes!!\n",
    "    positions = np.transpose(np.matmul(M0,positions.T))\n",
    "\n",
    "    # cut_logic = (positions[:,2] > 0.01 ) * (positions[:,2] < 0.1 )\n",
    "    return positions\n",
    "\n",
    "def cut_by_cylinder(positions,r_factor= .99 ,showplot = False):\n",
    "    dd = np.sqrt( (positions[:,0] - c_cylinder[0])**2 + (positions[:,1] - c_cylinder[1])**2 )\n",
    "\n",
    "    logic = dd < r_factor*r_cylinder\n",
    "\n",
    "    if showplot:\n",
    "\n",
    "        # easy3d(positions[::10,:])\n",
    "        positions = positions[logic,:]\n",
    "        easy3d(positions[:,:])\n",
    "\n",
    "        plt.figure()\n",
    "        plt.hist(dd)\n",
    "        plt.show()\n",
    "\n",
    "    return logic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A few simple plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting just pointcloud data\n",
    "def cheap3d(positions,rgb = None, new=True):\n",
    "    from matplotlib import rcParams\n",
    "    rcParams['font.family'] = 'serif'\n",
    "    #   3D plot of the\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    X, Y, Z = positions[:,0],positions[:,1],positions[:,2]\n",
    "\n",
    "    #   3D plot of Sphere\n",
    "    if new:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "    else:\n",
    "        ax = plt.gca()\n",
    "        ax = ax.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "    if rgb is None:\n",
    "        ax.scatter(X, Y, Z, zdir='z', s=10, c='b',rasterized=True)\n",
    "    else:\n",
    "        ax.scatter(X, Y, Z, zdir='z', s=6, c=rgb/255,rasterized=True)\n",
    "#     ax.set_aspect('equal')\n",
    "    #ax.set_xlim3d(-35, 35)\n",
    "    #ax.set_ylim3d(-35,35)\n",
    "    #ax.set_zlim3d(-70,0)\n",
    "    ax.set_xlabel('$x$ (mm)',fontsize=16)\n",
    "    ax.set_ylabel('\\n$y$ (mm)',fontsize=16)\n",
    "    zlabel = ax.set_zlabel('\\n$z$ (mm)',fontsize=16)\n",
    "\n",
    "    max_range = np.array([X.max()-X.min(), Y.max()-Y.min(), Z.max()-Z.min()]).max() / 2.0\n",
    "\n",
    "    mid_x = (X.max()+X.min()) * 0.5\n",
    "    mid_y = (Y.max()+Y.min()) * 0.5\n",
    "    mid_z = (Z.max()+Z.min()) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting pointcloud data with keypoints\n",
    "def cheap4d(pos,keyp,keyp_idx,rgb = None, new=True):\n",
    "    from matplotlib import rcParams\n",
    "    rcParams['font.family'] = 'serif'\n",
    "    #   3D plot of the\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    X, Y, Z = pos[:,0],pos[:,1],pos[:,2]\n",
    "\n",
    "    #   3D plot of Sphere\n",
    "    if new:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "    else:\n",
    "        ax = plt.gca()\n",
    "        ax = ax.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "    if rgb is None:\n",
    "        ax.scatter(X, Y, Z, zdir='z', s=3, c='k', alpha = .1,rasterized=True)\n",
    "    else:\n",
    "        ax.scatter(X, Y, Z, zdir='z', s=6, c=rgb/255,alpha = .5,rasterized=True)\n",
    "#     ax.set_aspect('equal')\n",
    "    #ax.set_xlim3d(-35, 35)\n",
    "    #ax.set_ylim3d(-35,35)\n",
    "    #ax.set_zlim3d(-70,0)\n",
    "    \n",
    "    body_colors = ['dodgerblue','red','lime','orange']\n",
    "    for i,body in enumerate(keyp_idx):\n",
    "        ax.scatter(keyp[i,0], keyp[i,1], keyp[i,2], zdir='z', s=100, c=body_colors[body],rasterized=True)\n",
    "    \n",
    "    ax.set_xlabel('$x$ (mm)',fontsize=16)\n",
    "    ax.set_ylabel('\\n$y$ (mm)',fontsize=16)\n",
    "    zlabel = ax.set_zlabel('\\n$z$ (mm)',fontsize=16)\n",
    "\n",
    "    max_range = np.array([X.max()-X.min(), Y.max()-Y.min(), Z.max()-Z.min()]).max() / 2.0\n",
    "\n",
    "    mid_x = (X.max()+X.min()) * 0.5\n",
    "    mid_y = (Y.max()+Y.min()) * 0.5\n",
    "    mid_z = (Z.max()+Z.min()) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "    plt.show()\n",
    "plt.close('all')\n",
    "# cheap4d(pos[::9],keyp,keyp_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrappers to load pairs of depth and color images, load keypoints coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dc_frames(frame,dev,d_files,png_files):\n",
    "    # get the frame # from the master table\n",
    "    # load the frame and the keypoints\n",
    "    # if the d is numpy\n",
    "#     d_image = np.load(d_files[dev][frame])\n",
    "    #else if it is png\n",
    "    d_image = cv2.imread(d_files[dev][frame],-1)\n",
    "    \n",
    "#     c_image = cv2.imread(png_files[dev][frame])\n",
    "#     c_image = np.zeros((240,320,3),dtype='uint8')\n",
    "    # if there is a cutoff on the top?\n",
    "#     c_image[30:,:,:] = cv2.imread(png_files[dev][frame])\n",
    "    c_image = cv2.imread(png_files[dev][frame],-1)\n",
    "    return c_image,d_image\n",
    "\n",
    "# make a figure to 'unpack the integers'\n",
    "def unpack_keypoints(keyp_datasets,dev,raw_frame):\n",
    "    # some unpack index wrangling\n",
    "    raw_line = keyp_datasets[dev][raw_frame]\n",
    "    fourth_length = int(len(raw_line)/4)\n",
    "    xy = raw_line[:(2*fourth_length)].reshape((-1,2))\n",
    "    pxy = raw_line[(2*fourth_length):-fourth_length]/100.\n",
    "    score_idx = raw_line[-fourth_length:]\n",
    "    return xy, pxy, score_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which loads a single frame with keypoints\n",
    "dev = 0\n",
    "frame = 1000\n",
    "def load_d_and_keyp(frame,dev):\n",
    "    # get the frame # from the master table\n",
    "    frame = timing['master_frame_table'][frame,dev]\n",
    "    # # load the frame and the keypoints\n",
    "    # d_image = np.load(d_files[dev][raw_frame])\n",
    "    c_image,d_image = load_dc_frames(frame,dev,d_files,png_files)\n",
    "    dac_image =  align_d_to_c(d_image,c_image,dev,geometry)\n",
    "    xy, pxy, score_idx = unpack_keypoints(keyp_datasets,dev,frame)\n",
    "\n",
    "    # scale the keypoints up to the color space, remember the 32 offset\n",
    "    # make the resolution correct, i.e. set the height to 192\n",
    "    # ALSO remember that there was a 30 px cut\n",
    "    pad_top = 8\n",
    "    pad_bottom = 10\n",
    "    # im = im[pad_top:-pad_bottom,:,:]\n",
    "    xy_cij = 4 * xy + np.array([pad_top+30,0])\n",
    "    \n",
    "    high_res = True\n",
    "    if high_res:\n",
    "        # size is \n",
    "        pad_right = 0\n",
    "        pad_top = 480-448 - 2\n",
    "        pad_bottom = 2\n",
    "        # im = im[pad_top:-pad_bottom,:,:]\n",
    "        xy_cij = 4 * xy + np.array([pad_top,0])        \n",
    "\n",
    "    # move the keypoints from color pixel space to depth pixel space\n",
    "    # discussion here: https://github.com/IntelRealSense/librealsense/issues/2137\n",
    "\n",
    "    #TODO take average around point!\n",
    "    xy_d = dac_image[xy_cij[:,0],xy_cij[:,1]] \n",
    "    \n",
    "    xy_d = np.zeros_like(xy[:,0])\n",
    "    for i in range(xy.shape[0]):\n",
    "        if high_res:\n",
    "            pixels = dac_image[np.meshgrid( np.arange(-4,5) + xy_cij[i,0], np.arange(-4,5) + xy_cij[i,1])]\n",
    "        else:\n",
    "            pixels = dac_image[np.meshgrid( np.arange(-2,3) + xy_cij[i,0], np.arange(-2,3) + xy_cij[i,1])]\n",
    "            \n",
    "        xy_d[i] = np.nanmax( [np.median(pixels[pixels > 0].ravel()) , 0])\n",
    "            \n",
    "\n",
    "\n",
    "    # convert the keypoints to XYZ\n",
    "    fx,fy,ppx,ppy,depth_scale,fps,frame_width,frame_height = geometry['d_cam_params'][dev]\n",
    "    fps,frame_width,frame_height = fps.astype('int'),frame_width.astype('int'),frame_height.astype('int')\n",
    "    fx_c,fy_c,ppx_c,ppy_c,_,_,frame_width_c,frame_height_c =  geometry['c_cam_params'][dev]\n",
    "\n",
    "    # FIX the geometry due to downsample\n",
    "    # divide the xy because downsample\n",
    "    fx,fy,ppx,ppy = fx/2,fy/2,ppx/2,ppy/2\n",
    "#     fx_c,fy_c,ppx_c,ppy_c = fx_c/2,fy_c/2,ppx_c/2,ppy_c/2\n",
    "    frame_width,frame_height = int(frame_width/2),int(frame_height/2)\n",
    "\n",
    "\n",
    "    z_c = xy_d*depth_scale # +1e-6\n",
    "\n",
    "    # and now use pinhole cam function to get the x and y\n",
    "    x_c = (xy_cij[:,1] - ppx_c) * z_c / fx_c\n",
    "    y_c = (xy_cij[:,0] - ppy_c) * z_c / fy_c    \n",
    "\n",
    "    # # and pack to a stack of positions!\n",
    "    keyp_color_space = np.vstack((x_c,y_c,z_c)).T    \n",
    "\n",
    "    # SWING THESE POSITIONS TO THE DEPTH SPACE\n",
    "    R_extr = geometry['R_extrinsics'][dev]\n",
    "    t_extr = geometry['t_extrinsics'][dev]\n",
    "    keyp_depth_space = np.einsum('ij,aj->ai',R_extr.T,(keyp_color_space - t_extr ))\n",
    "\n",
    "    # also unpack the depth points!\n",
    "    # get the expanded once more\n",
    "    pi,pj = np.where( (d_image>0) )\n",
    "\n",
    "    # pi,pj = np.where( (d>0 ) ) # simply all\n",
    "    # get the depth of the masked pixels as a raveled list\n",
    "    dij = d_image[pi,pj]\n",
    "\n",
    "    # z is easy to calculate, it's just the depth\n",
    "    z_m = dij*depth_scale # +1e-6\n",
    "    # z_m = np.clip(z_m,0.,.5)\n",
    "\n",
    "    # and now use pinhole cam function to get the x and y\n",
    "    x_m = (pj - ppx) * z_m / fx\n",
    "    y_m = (pi - ppy) * z_m / fy\n",
    "\n",
    "    d_positions = np.vstack((x_m,y_m,z_m)).T    \n",
    "    \n",
    "    points_to_cam = np.linalg.norm(d_positions,axis=1)\n",
    "\n",
    "    d_world = apply_rigid_transformation(d_positions,geometry['R_world'][dev],geometry['t_world'][dev])\n",
    "    keyp_world = apply_rigid_transformation(keyp_depth_space,geometry['R_world'][dev],geometry['t_world'][dev])    \n",
    "    \n",
    "    # add the distance as a fourth dimension to the positions\n",
    "    d_world_weights = np.hstack([d_world,points_to_cam[:,np.newaxis]])\n",
    "    \n",
    "    return d_world_weights,keyp_world,pxy,score_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a frame, to make sure everything looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the keypoints in depth space\n",
    "# plt.figure()\n",
    "# dummy = (d_image%255)/5\n",
    "# dummy[xy_cij[:,0],xy_cij[:,1]] = 255\n",
    "# plt.imshow(dummy)\n",
    "# # plt.plot(xy_cij[:,0],xy_cij[:,1],'or')\n",
    "if True:\n",
    "    frame = 6000 + 1000\n",
    "    c_image,d_image = load_dc_frames(frame,dev,d_files,png_files)\n",
    "    dac_image =  align_d_to_c(d_image,c_image,dev,geometry)\n",
    "    xy, pxy, score_idx = unpack_keypoints(keyp_datasets,dev,frame)\n",
    "    # scale the keypoints up to the color space, remember the 32 offset\n",
    "    # make the resolution correct, i.e. set the height to 192\n",
    "    # ALSO remember that there was a 30 px cut\n",
    "    \n",
    "    # NB!! CHECK THIS CUTOFF\n",
    "#     cutoff = 0.5\n",
    "#     xy = xy[pxy>0.5,:]\n",
    "    \n",
    "    pad_top = 8\n",
    "    pad_bottom = 10\n",
    "    # im = im[pad_top:-pad_bottom,:,:]\n",
    "    xy_cij = 4 * xy + np.array([pad_top+30,0])\n",
    "    \n",
    "    high_res = True\n",
    "    if high_res:\n",
    "        pad_right = 0\n",
    "        pad_top = 480-448 - 2\n",
    "        pad_bottom = 2        # im = im[pad_top:-pad_bottom,:,:]\n",
    "        xy_cij = 4 * xy + np.array([pad_top,0])        \n",
    "    \n",
    "    # plot the keypoints in depth space\n",
    "    plt.figure(figsize = (10,6))\n",
    "    plt.subplot(1,2,1)\n",
    "#     dummy = (np.mean(c_image,2))/2\n",
    "    dummy = c_image/2\n",
    "\n",
    "    dummy[xy_cij[:,0],xy_cij[:,1]] = 255\n",
    "    \n",
    "    plt.imshow(dummy)\n",
    "    plt.title('Color image, high value pixels are keypoints')\n",
    "    # plt.plot(xy_cij[:,0],xy_cij[:,1],'or')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    dummy = (dac_image%255)/(2)\n",
    "    dummy[xy_cij[:,0],xy_cij[:,1]] = 255\n",
    "#     plt.plot(xy_cij[:,0],xy_cij[:,1],'or')\n",
    "#     dummy[] = 255\n",
    "    plt.imshow(dummy)\n",
    "    plt.title('Depth aligned to color image, high value pixels are keypoints')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/pre_depth_01.png\" width = 100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a wrapper for loading and composing a full 3D frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the point cloud, the keypoints fof a frame!\n",
    "\n",
    "def load_d_and_keyp_all(frame):\n",
    "    d_world_list = [None]*4\n",
    "    keyp_list = [None]*4 \n",
    "    pkeyp_list = [None]*4 \n",
    "    score_idx_list = [None]*4\n",
    "    for dev in range(4):\n",
    "        d_world,keyp_world,pkeyp,score_idx = load_d_and_keyp(frame,dev)\n",
    "        d_world_list[dev] = d_world\n",
    "        keyp_list[dev] = keyp_world\n",
    "        score_idx_list[dev] = score_idx\n",
    "        pkeyp_list[dev] = pkeyp\n",
    "        \n",
    "    return np.concatenate(d_world_list), np.concatenate(keyp_list), np.concatenate(pkeyp_list), np.concatenate(score_idx_list)\n",
    "\n",
    "def load_full_frame(frame):\n",
    "    pos, keyp, pkeyp, keyp_idx = load_d_and_keyp_all(frame)\n",
    "    # split out, \n",
    "    pos, points_to_cam = pos[:,:3],pos[:,3]\n",
    "    # TODO could clean this up, sort of silly right now\n",
    "    \n",
    "    cut_logic = cut_by_floor_roof(pos,floor_point,floor_normal,floor_cut=0.006,roof_cut=0.15)\n",
    "    \n",
    "    pos = align_by_floor(pos,floor_point,M0)\n",
    "    keyp = align_by_floor(keyp,floor_point,M0)\n",
    "\n",
    "    cyl_logic = cut_by_cylinder(pos,r_factor= 1.,showplot = False)\n",
    "    \n",
    "    # select points above the floor and inside the cylinder\n",
    "    selection_logic = cyl_logic*cut_logic\n",
    "    pos = pos[selection_logic,:]\n",
    "\n",
    "#     pos = pos[cyl_logic]\n",
    "    \n",
    "#     keyp_logic = cut_by_cylinder(keyp,r_factor= .99,showplot = False)\n",
    "    \n",
    "    keyp_logic = (pkeyp > .5) * cut_by_cylinder(keyp,r_factor= .99,showplot = False)\n",
    "\n",
    "    # and the weigths as well!\n",
    "    pos_weights = points_to_cam[selection_logic]**2\n",
    "\n",
    "    # TODO!!!! CENTER EVERYTHING BY THE CENTER OF THE CYLINDER\n",
    "    \n",
    "    pos[:,:2] = pos[:,:2] - c_cylinder[np.newaxis,:]\n",
    "    keyp[:,:2] = keyp[:,:2] - c_cylinder[np.newaxis,:]\n",
    "    \n",
    "    return pos, pos_weights, keyp[keyp_logic,:], pkeyp[keyp_logic], keyp_idx[keyp_logic]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Again, check with a few plots that it looks fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrelli/anaconda2/envs/mousepose/lib/python3.6/site-packages/ipykernel_launcher.py:39: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.01 0.89 0.58 0.75 1.   0.87 0.68]\n",
      "[0.88 0.6  0.88 0.88 1.07 0.82 1.02 0.82]\n",
      "[0.75 0.83 0.82 0.51 0.71 0.7  0.65 0.63 0.71 0.92 0.9  0.88 0.79]\n",
      "[1.37 0.72 0.59 0.68 0.99 0.9  0.7  1.09 0.67]\n",
      "[1.78 0.61 0.88 0.58 0.64 1.14 0.58 0.51]\n",
      "[1.3  0.64 0.86 1.56 0.64 0.97 0.76 0.64 1.26 0.87 0.74 0.71 0.78 0.59]\n",
      "[0.88 0.77 0.57 1.11 0.85 0.8  0.86 0.57 0.73 0.54 0.56 0.73 0.77 0.85]\n",
      "[1.01 0.6  0.99 0.58 0.54 0.8  0.71 0.9 ]\n",
      "[1.2  0.85 1.1  0.79 0.66 0.62 0.51 0.76]\n",
      "[0.72 1.47 0.87 0.77]\n"
     ]
    }
   ],
   "source": [
    "plt.close('all')\n",
    "frame = 6000+1000\n",
    "for frame in np.linspace(5*30,5*60*30,10,dtype='int'):\n",
    "    pos, pos_weights, keyp, pkeyp, keyp_idx = load_full_frame(frame)\n",
    "    \n",
    "    print(pkeyp)\n",
    "    cheap4d(pos[::3],keyp,keyp_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/pre_depth_02.png\" width = 50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheap3d(pos[::3],rgb = pos_weights[::3]/(pos_weights.max()), new=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/pre_depth_03.png\" width = 50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make functions to pack and unpack 3D data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make functions to pack and unpack data to a single string\n",
    "def pack_to_jagged(pos, pos_weights, keyp, pkeyp, keyp_idx):\n",
    "    ''' Takes the NX3, N, Mx3, M, M shapes and packs to a single float16\n",
    "    We ravel the position, ravel the keyp, stack everything and \n",
    "    - importantly - we also save M, the number of keypoints'''\n",
    "    n_keyp = keyp_idx.shape[0]\n",
    "    block = np.hstack([pos,pos_weights[:,np.newaxis]])\n",
    "    jagged_line = np.hstack((block.ravel(),keyp.ravel(),pkeyp,keyp_idx,n_keyp))\n",
    "    return jagged_line\n",
    "\n",
    "jagged_line = pack_to_jagged(pos, pos_weights, keyp, pkeyp, keyp_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_from_jagged(jagged_line):\n",
    "    ''' THE REVESER SO HERE IT UNPACKS AGAIN SO THE DATA CAN BE SAVED\n",
    "    AS A JAGGED H5PY DATASET \n",
    "    FROM OTHER: Takes the NX3, N, Mx3, M, M shapes and packs to a single float16\n",
    "    We ravel the position, ravel the keyp, stack everything and \n",
    "    - importantly - we also save M, the number of keypoints'''\n",
    "    n_keyp = int(jagged_line[-1])\n",
    "    keyp_idx2 = jagged_line[-(1+n_keyp):-1].astype('int')\n",
    "    pkeyp2 = jagged_line[-(1+2*n_keyp):-(1+n_keyp)]\n",
    "    keyp2 = jagged_line[-(1+5*n_keyp):-(1+2*n_keyp)].reshape((n_keyp,3))\n",
    "    block2 = jagged_line[:-(1+5*n_keyp)].reshape((-1,4))\n",
    "    pos2,pos_weights2 = block2[:,:3], block2[:,3]\n",
    "    return pos2, pos_weights2, keyp2, pkeyp2, keyp_idx2\n",
    "\n",
    "pos2, pos_weights2, keyp2, pkeyp2, keyp_idx2 = unpack_from_jagged(jagged_line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process all frames and dump to hdf5 file as jagged arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425487f3cd2a44d89962c1c0309a25c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=73123), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrelli/anaconda2/envs/mousepose/lib/python3.6/site-packages/ipykernel_launcher.py:39: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with 73123 frames!\n"
     ]
    }
   ],
   "source": [
    "# NOW we actually pre-process the data, required for saving and compressing the data\n",
    "\n",
    "# OK OK OK, now select the reference camera!\n",
    "n_frames = len(timing['reference_stamps'])\n",
    "\n",
    "# open a file for the \n",
    "with h5py.File(top_folder_0+'/pre_processed_frames.hdf5', mode='w') as hdf5_file:\n",
    "    # make the variable length dataset, go with float16 for now\n",
    "    dt = h5py.special_dtype(vlen=np.dtype('float16'))\n",
    "    hdf5_file.create_dataset('dataset', (n_frames,), dtype=dt)\n",
    "    \n",
    "    # now, loop over the frames and save them\n",
    "    for frame in tqdm_notebook(range(n_frames)):\n",
    "        # load the frame\n",
    "        pos, pos_weights, keyp, pkeyp, keyp_idx = load_full_frame(frame)\n",
    "        # pack to a single line for jagged h5py\n",
    "        jagged_line = pack_to_jagged(pos[::2], pos_weights[::2], keyp, pkeyp, keyp_idx)\n",
    "        # write to the h5py file\n",
    "        hdf5_file['dataset'][frame] = jagged_line.astype('float16')\n",
    "        \n",
    "#         # quic_look:\n",
    "#         if frame > 6000:\n",
    "#             break\n",
    "    print(\"Done with {} frames!\".format(n_frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if file is good: Reload data from hdf5 file, unpack and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['dataset']>\n",
      "82158\n",
      "[0 1 1 1 1 1 2 2 2 3 3 1 1 1 2 2 3 3 3 0 1 1 1 2 2 3 3 0 1 1 2 2 2 3]\n",
      "[0.2  0.63 0.6  0.2  0.91 0.15 0.21 0.24 0.8  0.79 0.52 0.66 0.35 0.81\n",
      " 0.14 0.15 0.39 0.21 0.33 0.15 1.06 0.17 0.3  0.9  0.44 0.6  0.22 1.63\n",
      " 0.4  0.77 0.16 0.79 0.2  0.42]\n"
     ]
    }
   ],
   "source": [
    "# now, try to load some data, to see if it is OK\n",
    "with h5py.File(top_folder_0+'/pre_processed_frames.hdf5', mode='r') as hdf5_file:\n",
    "    print(hdf5_file.keys())\n",
    "    print(len(hdf5_file['dataset']))\n",
    "    jagged_line = hdf5_file['dataset'][1190] \n",
    "    \n",
    "    pos, pos_weights, keyp, pkeyp, keyp_idx = unpack_from_jagged(jagged_line)\n",
    "    print(keyp_idx)\n",
    "    print(pkeyp)\n",
    "\n",
    "    cheap4d(pos,keyp,keyp_idx)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Make a plot to show merging of four clouds, for the manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
