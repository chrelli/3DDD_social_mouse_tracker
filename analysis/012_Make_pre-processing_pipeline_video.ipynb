{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# OK, now make a function to process images, collapse to a pointcloud and dump to an h5py file\n",
    "\n",
    "%matplotlib qt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys, os, pickle\n",
    "import cv2\n",
    "from colour import Color\n",
    "import h5py\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import glob\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the timing and geometry, load depth images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['start_frame', 'end_frame', 'd_cam_params', 'c_cam_params', 'R_extrinsics', 't_extrinsics', 'R_world', 't_world', 'M0', 'floor_point', 'floor_normal', 'c_cylinder', 'r_cylinder'])\n",
      "dict_keys(['master_frame_table', 'reference_time_cam', 'reference_stamps', 'time_stamps', 'shifted_stamps'])\n"
     ]
    }
   ],
   "source": [
    "# load the geometry\n",
    "top_folder_0 = '/media/chrelli/Data0/recording_20190905-115115'\n",
    "top_folder_1 = '/media/chrelli/Data1/recording_20190905-115115'\n",
    "\n",
    "scene_folders = [top_folder_0,top_folder_0,top_folder_1,top_folder_1]\n",
    "import pickle\n",
    "geometry = pickle.load( open( scene_folders[0]+'/geometry.pkl', \"rb\" ) ) \n",
    "timing = pickle.load( open( scene_folders[0]+'/timing.pkl', \"rb\" ) )\n",
    "print(geometry.keys())\n",
    "print(timing.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also make a list of all the frames to process\n",
    "# make a list of the cameras!\n",
    "d_files = [glob.glob(scene_folders[i] + '/npy_raw/dev' +str(i) +'_d_*.npy') for i in range(4)]\n",
    "d_files = [sorted(f) for f in d_files]\n",
    "\n",
    "png_files = [glob.glob(scene_folders[i] + '/npy_raw/dev' +str(i) +'_cad_*.png') for i in range(4)]\n",
    "png_files = [sorted(f) for f in png_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['dataset']>\n",
      "74962\n",
      "[21 50 23 29 22 48 23 50 24 40 58 85 98 81 90  0  1  1  2  3]\n",
      "<KeysViewHDF5 ['dataset']>\n",
      "74791\n",
      "[ 32  35  34  41  22  61  40  33  25  65  31  58  23  50 247  70  95  80\n",
      "  78  84  85   0   1   1   2   2   3   3]\n",
      "<KeysViewHDF5 ['dataset']>\n",
      "74801\n",
      "[20 19 33 51 31 48 23 17 40 46 30 19 99 73 74 54 76 77  0  1  1  1  2  3]\n",
      "<KeysViewHDF5 ['dataset']>\n",
      "74785\n",
      "[ 13  44  22  10  16  43  17  45  26  23  19  32 163  64  94  77  76  91\n",
      "   0   1   1   2   3   3]\n"
     ]
    }
   ],
   "source": [
    "# load all the keypoint data (since it's so tiny!)\n",
    "# OK, try to see if the data is in the h5py file\n",
    "keyp_datasets = []\n",
    "for dev in range(4):\n",
    "    with h5py.File(top_folder_0+'/keypoints_'+str(dev)+'.hdf5', mode='r') as hdf5_file:\n",
    "        print(hdf5_file.keys())\n",
    "        print(len(hdf5_file['dataset']))\n",
    "        print( hdf5_file['dataset'][500] )\n",
    "        keyp_datasets.append(hdf5_file['dataset'][...])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a function to align depth to color images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_d_to_c(d_image,c_image,dev,geometry):\n",
    "    # todo can be sped up    \n",
    "    pi,pj = np.where( (d_image>0) ) # simply all\n",
    "    dij = d_image[pi,pj]\n",
    "\n",
    "    fx,fy,ppx,ppy,depth_scale,fps,frame_width,frame_height = geometry['d_cam_params'][dev]\n",
    "    fps,frame_width,frame_height = fps.astype('int'),frame_width.astype('int'),frame_height.astype('int')\n",
    "    fx_c,fy_c,ppx_c,ppy_c,_,_,_,_ = geometry['c_cam_params'][dev]\n",
    "    \n",
    "    # FIX the geometry due to downsample\n",
    "    # divide the xy because downsample\n",
    "    fx,fy,ppx,ppy = fx/2,fy/2,ppx/2,ppy/2\n",
    "    fx_c,fy_c,ppx_c,ppy_c = fx_c/2,fy_c/2,ppx_c/2,ppy_c/2\n",
    "    frame_width,frame_height = int(frame_width/2),int(frame_height/2)\n",
    "\n",
    "    \n",
    "    z_m = dij*depth_scale # +1e-6\n",
    "\n",
    "    # and now use pinhole cam function to get the x and y\n",
    "    x_m = (pj - ppx) * z_m / fx\n",
    "    y_m = (pi - ppy) * z_m / fy    \n",
    "\n",
    "    # and pack to a stack of positions!\n",
    "    positions_depth_space = np.vstack((x_m,y_m,z_m)).T    \n",
    "\n",
    "    # swing the depth positions to the color space\n",
    "    R_extr = geometry['R_extrinsics'][dev]\n",
    "    t_extr = geometry['t_extrinsics'][dev]\n",
    "    positions_color_space = np.einsum('ij,aj->ai',R_extr,positions_depth_space) + t_extr\n",
    "\n",
    "    # now we can caculate cu and cj, the index in the color frame of each point\n",
    "    ci = np.round(positions_color_space[:,1] * fy_c / positions_color_space[:,2] + ppy_c)\n",
    "    cj = np.round(positions_color_space[:,0] * fx_c / positions_color_space[:,2] + ppx_c)\n",
    "\n",
    "    # make sure that they are good (actually, should probably set to zero outside)\n",
    "    ci = np.clip(ci,0,frame_height-1).astype(int)\n",
    "    cj = np.clip(cj,0,frame_width-1).astype(int)    \n",
    "\n",
    "    # depth aligned to color\n",
    "    \n",
    "    dac_image = np.zeros((frame_height,frame_width))\n",
    "    dac_mask = np.zeros((frame_height,frame_width))\n",
    "    # return the depth in meters\n",
    "    dac_image[ci,cj] = dij\n",
    "    dac_mask[ci,cj] = 1\n",
    "    sigma_g = 3\n",
    "    # dac_image = cv2.medianBlur(dac_image.astype('uint16'),5)\n",
    "    # dac_image = cv2.GaussianBlur(dac_image,(sigma_g,sigma_g),0)/cv2.GaussianBlur(dac_mask,(sigma_g,sigma_g),0)\n",
    "    # dac_image = dac_image[:,:,0]/dac_image[:,:,1]\n",
    "    return dac_image.astype('uint16')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions to align, merge and cut the pointclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "#%% also set up the cylinder filtering!\n",
    "c_cylinder = geometry['c_cylinder']\n",
    "r_cylinder = geometry['r_cylinder']\n",
    "floor_point = geometry['floor_point']\n",
    "floor_normal = geometry['floor_normal']\n",
    "M0 = geometry['M0']\n",
    "\n",
    "def apply_rigid_transformation(positions,R,t):\n",
    "    # takes postions as a Nx3 vector and applies rigid transformation\n",
    "    # make matrices\n",
    "    A = np.asmatrix(positions)\n",
    "    R = np.asmatrix(R)\n",
    "    t = np.asmatrix(t).T\n",
    "\n",
    "    # Matrix way:\n",
    "    n = A.shape[0]\n",
    "    A2 = np.matmul(R,A.T) + np.tile(t, (1, n))\n",
    "\n",
    "    # print(str(i)+' after transform: '+str(A2.shape))\n",
    "    # make it an array?\n",
    "    return np.asarray(A2.T)\n",
    "\n",
    "\n",
    "def cut_by_floor_roof(positions,floor_point,floor_normal,floor_cut=0.005,roof_cut=0.01):\n",
    "    \"\"\"\n",
    "    Function to cut away the floor w/o a need to rotate the points fikst, just use the dot product trick\n",
    "    # cut away floor?\n",
    "    # use the equation of the plane: http://tutorial.math.lamar.edu/Classes/CalcIII/EqnsOfPlanes.aspx\n",
    "    # and evaluate this to check if it's above or below: https://stackoverflow.com/questions/15688232/check-which-side-of-a-plane-points-are-on\n",
    "\n",
    "    \"\"\"\n",
    "    # find the first coefficients of the equation of the plane!\n",
    "    plane_coeffs = floor_normal\n",
    "\n",
    "        # find a point above the plane!\n",
    "    hover_point = floor_point + floor_normal * floor_cut\n",
    "    roof_point = floor_point + floor_normal * roof_cut\n",
    "        # calculate d, which is the dot product between a point on the plane and the normal\n",
    "    floor_d = np.dot(floor_normal,hover_point)\n",
    "    roof_d = np.dot(floor_normal,roof_point)\n",
    "\n",
    "    # the idea is to calc ax+by+cz+d where abc is the normal and xyz is the point being tested\n",
    "    # now do the dot product as the logic to pflip on the sign (don't care about equal to)\n",
    "    #test_prod = np.dot(positions,plane_coeffs[0:3])\n",
    "    # einsum is faster!\n",
    "    test_prod = np.einsum('j,ij->i',plane_coeffs,positions)\n",
    "\n",
    "\n",
    "    above_logic = (test_prod > floor_d) * (test_prod < roof_d)\n",
    "    return above_logic\n",
    "\n",
    "\n",
    "def align_by_floor(positions,floor_point,M0):\n",
    "    positions = positions - floor_point\n",
    "    # rotate!\n",
    "    #TODO desperate need to convert everything to 4D transformations!! Here translation is first, then rotate. Above it's the other way around Yikes!!\n",
    "    positions = np.transpose(np.matmul(M0,positions.T))\n",
    "\n",
    "    # cut_logic = (positions[:,2] > 0.01 ) * (positions[:,2] < 0.1 )\n",
    "    return positions\n",
    "\n",
    "def cut_by_cylinder(positions,r_factor= .99 ,showplot = False):\n",
    "    dd = np.sqrt( (positions[:,0] - c_cylinder[0])**2 + (positions[:,1] - c_cylinder[1])**2 )\n",
    "\n",
    "    logic = dd < r_factor*r_cylinder\n",
    "\n",
    "    if showplot:\n",
    "\n",
    "        # easy3d(positions[::10,:])\n",
    "        positions = positions[logic,:]\n",
    "        easy3d(positions[:,:])\n",
    "\n",
    "        plt.figure()\n",
    "        plt.hist(dd)\n",
    "        plt.show()\n",
    "\n",
    "    return logic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A few simple plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting just pointcloud data\n",
    "def cheap3d(positions,rgb = None, new=True):\n",
    "    from matplotlib import rcParams\n",
    "    rcParams['font.family'] = 'serif'\n",
    "    #   3D plot of the\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    X, Y, Z = positions[:,0],positions[:,1],positions[:,2]\n",
    "\n",
    "    #   3D plot of Sphere\n",
    "    if new:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "    else:\n",
    "        ax = plt.gca()\n",
    "        ax = ax.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "    if rgb is None:\n",
    "        ax.scatter(X, Y, Z, zdir='z', s=10, c='b',rasterized=True)\n",
    "    else:\n",
    "        ax.scatter(X, Y, Z, zdir='z', s=6, c=rgb/255,rasterized=True)\n",
    "#     ax.set_aspect('equal')\n",
    "    #ax.set_xlim3d(-35, 35)\n",
    "    #ax.set_ylim3d(-35,35)\n",
    "    #ax.set_zlim3d(-70,0)\n",
    "    ax.set_xlabel('$x$ (mm)',fontsize=16)\n",
    "    ax.set_ylabel('\\n$y$ (mm)',fontsize=16)\n",
    "    zlabel = ax.set_zlabel('\\n$z$ (mm)',fontsize=16)\n",
    "\n",
    "    max_range = np.array([X.max()-X.min(), Y.max()-Y.min(), Z.max()-Z.min()]).max() / 2.0\n",
    "\n",
    "    mid_x = (X.max()+X.min()) * 0.5\n",
    "    mid_y = (Y.max()+Y.min()) * 0.5\n",
    "    mid_z = (Z.max()+Z.min()) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting pointcloud data with keypoints\n",
    "def cheap4d(pos,keyp,keyp_idx,rgb = None, new=True):\n",
    "    from matplotlib import rcParams\n",
    "    rcParams['font.family'] = 'serif'\n",
    "    #   3D plot of the\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    X, Y, Z = pos[:,0],pos[:,1],pos[:,2]\n",
    "\n",
    "    #   3D plot of Sphere\n",
    "    if new:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "    else:\n",
    "        ax = plt.gca()\n",
    "        ax = ax.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "    if rgb is None:\n",
    "        ax.scatter(X, Y, Z, zdir='z', s=10, c='k', alpha = .1,rasterized=True)\n",
    "    else:\n",
    "        ax.scatter(X, Y, Z, zdir='z', s=6, c=rgb/255,alpha = .5,rasterized=True)\n",
    "#     ax.set_aspect('equal')\n",
    "    #ax.set_xlim3d(-35, 35)\n",
    "    #ax.set_ylim3d(-35,35)\n",
    "    #ax.set_zlim3d(-70,0)\n",
    "    \n",
    "    body_colors = ['dodgerblue','red','lime','orange']\n",
    "    for i,body in enumerate(keyp_idx):\n",
    "        ax.scatter(keyp[i,0], keyp[i,1], keyp[i,2], zdir='z', s=100, c=body_colors[body],rasterized=True)\n",
    "    \n",
    "    ax.set_xlabel('$x$ (mm)',fontsize=16)\n",
    "    ax.set_ylabel('\\n$y$ (mm)',fontsize=16)\n",
    "    zlabel = ax.set_zlabel('\\n$z$ (mm)',fontsize=16)\n",
    "\n",
    "    max_range = np.array([X.max()-X.min(), Y.max()-Y.min(), Z.max()-Z.min()]).max() / 2.0\n",
    "\n",
    "    mid_x = (X.max()+X.min()) * 0.5\n",
    "    mid_y = (Y.max()+Y.min()) * 0.5\n",
    "    mid_z = (Z.max()+Z.min()) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "    plt.show()\n",
    "plt.close('all')\n",
    "# cheap4d(pos[::9],keyp,keyp_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrappers to load pairs of depth and color images, load keypoints coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dc_frames(frame,dev,d_files,png_files):\n",
    "    # get the frame # from the master table\n",
    "    # load the frame and the keypoints\n",
    "    d_image = np.load(d_files[dev][frame])\n",
    "#     c_image = cv2.imread(png_files[dev][frame])\n",
    "    c_image = np.zeros((240,320,3),dtype='uint8')\n",
    "    c_image[30:,:,:] = cv2.imread(png_files[dev][frame])\n",
    "    return c_image,d_image\n",
    "\n",
    "# make a figure to 'unpack the integers'\n",
    "def unpack_keypoints(keyp_datasets,dev,raw_frame):\n",
    "    # some unpack index wrangling\n",
    "    raw_line = keyp_datasets[dev][raw_frame]\n",
    "    fourth_length = int(len(raw_line)/4)\n",
    "    xy = raw_line[:(2*fourth_length)].reshape((-1,2))\n",
    "    pxy = raw_line[(2*fourth_length):-fourth_length]/100.\n",
    "    score_idx = raw_line[-fourth_length:]\n",
    "    return xy, pxy, score_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which loads a single frame with keypoints\n",
    "dev = 0\n",
    "frame = 1000\n",
    "def load_d_and_keyp(frame,dev):\n",
    "    # get the frame # from the master table\n",
    "    frame = timing['master_frame_table'][frame,dev]\n",
    "    # # load the frame and the keypoints\n",
    "    # d_image = np.load(d_files[dev][raw_frame])\n",
    "    c_image,d_image = load_dc_frames(frame,dev,d_files,png_files)\n",
    "    dac_image =  align_d_to_c(d_image,c_image,dev,geometry)\n",
    "    xy, pxy, score_idx = unpack_keypoints(keyp_datasets,dev,frame)\n",
    "\n",
    "    # scale the keypoints up to the color space, remember the 32 offset\n",
    "    # make the resolution correct, i.e. set the height to 192\n",
    "    # ALSO remember that there was a 30 px cut\n",
    "    pad_top = 8\n",
    "    pad_bottom = 10\n",
    "    # im = im[pad_top:-pad_bottom,:,:]\n",
    "    xy_cij = 4 * xy + np.array([pad_top+30,0])\n",
    "\n",
    "    # move the keypoints from color pixel space to depth pixel space\n",
    "    # discussion here: https://github.com/IntelRealSense/librealsense/issues/2137\n",
    "\n",
    "    #TODO take average around point!\n",
    "    xy_d = dac_image[xy_cij[:,0],xy_cij[:,1]] \n",
    "    \n",
    "    xy_d = np.zeros_like(xy[:,0])\n",
    "    for i in range(xy.shape[0]):\n",
    "        pixels = dac_image[np.meshgrid( np.arange(-2,3) + xy_cij[i,0], np.arange(-2,3) + xy_cij[i,1])]\n",
    "        xy_d[i] = np.nanmax( [np.median(pixels[pixels > 0].ravel()) , 0])\n",
    "\n",
    "\n",
    "    # convert the keypoints to XYZ\n",
    "    fx,fy,ppx,ppy,depth_scale,fps,frame_width,frame_height = geometry['d_cam_params'][dev]\n",
    "    fps,frame_width,frame_height = fps.astype('int'),frame_width.astype('int'),frame_height.astype('int')\n",
    "    fx_c,fy_c,ppx_c,ppy_c,_,_,_,_ =  geometry['c_cam_params'][dev]\n",
    "\n",
    "    # FIX the geometry due to downsample\n",
    "    # divide the xy because downsample\n",
    "    fx,fy,ppx,ppy = fx/2,fy/2,ppx/2,ppy/2\n",
    "    fx_c,fy_c,ppx_c,ppy_c = fx_c/2,fy_c/2,ppx_c/2,ppy_c/2\n",
    "    frame_width,frame_height = int(frame_width/2),int(frame_height/2)\n",
    "\n",
    "\n",
    "    z_c = xy_d*depth_scale # +1e-6\n",
    "\n",
    "    # and now use pinhole cam function to get the x and y\n",
    "    x_c = (xy_cij[:,1] - ppx_c) * z_c / fx_c\n",
    "    y_c = (xy_cij[:,0] - ppy_c) * z_c / fy_c    \n",
    "\n",
    "    # # and pack to a stack of positions!\n",
    "    keyp_color_space = np.vstack((x_c,y_c,z_c)).T    \n",
    "\n",
    "    # SWING THESE POSITIONS TO THE DEPTH SPACE\n",
    "    R_extr = geometry['R_extrinsics'][dev]\n",
    "    t_extr = geometry['t_extrinsics'][dev]\n",
    "    keyp_depth_space = np.einsum('ij,aj->ai',R_extr.T,(keyp_color_space - t_extr ))\n",
    "\n",
    "    # also unpack the depth points!\n",
    "    # get the expanded once more\n",
    "    pi,pj = np.where( (d_image>0) )\n",
    "\n",
    "    # pi,pj = np.where( (d>0 ) ) # simply all\n",
    "    # get the depth of the masked pixels as a raveled list\n",
    "    dij = d_image[pi,pj]\n",
    "\n",
    "    # z is easy to calculate, it's just the depth\n",
    "    z_m = dij*depth_scale # +1e-6\n",
    "    # z_m = np.clip(z_m,0.,.5)\n",
    "\n",
    "    # and now use pinhole cam function to get the x and y\n",
    "    x_m = (pj - ppx) * z_m / fx\n",
    "    y_m = (pi - ppy) * z_m / fy\n",
    "\n",
    "    d_positions = np.vstack((x_m,y_m,z_m)).T    \n",
    "    \n",
    "    points_to_cam = np.linalg.norm(d_positions,axis=1)\n",
    "\n",
    "    d_world = apply_rigid_transformation(d_positions,geometry['R_world'][dev],geometry['t_world'][dev])\n",
    "    keyp_world = apply_rigid_transformation(keyp_depth_space,geometry['R_world'][dev],geometry['t_world'][dev])    \n",
    "    \n",
    "    # add the distance as a fourth dimension to the positions\n",
    "    d_world_weights = np.hstack([d_world,points_to_cam[:,np.newaxis]])\n",
    "    \n",
    "    return d_world_weights,keyp_world,pxy,score_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a frame, to make sure everything looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the keypoints in depth space\n",
    "# plt.figure()\n",
    "# dummy = (d_image%255)/5\n",
    "# dummy[xy_cij[:,0],xy_cij[:,1]] = 255\n",
    "# plt.imshow(dummy)\n",
    "# # plt.plot(xy_cij[:,0],xy_cij[:,1],'or')\n",
    "if True:\n",
    "    frame = 2000\n",
    "    c_image,d_image = load_dc_frames(frame,dev,d_files,png_files)\n",
    "    dac_image =  align_d_to_c(d_image,c_image,dev,geometry)\n",
    "    xy, pxy, score_idx = unpack_keypoints(keyp_datasets,dev,frame)\n",
    "    # scale the keypoints up to the color space, remember the 32 offset\n",
    "    # make the resolution correct, i.e. set the height to 192\n",
    "    # ALSO remember that there was a 30 px cut\n",
    "    pad_top = 8\n",
    "    pad_bottom = 10\n",
    "    # im = im[pad_top:-pad_bottom,:,:]\n",
    "    xy_cij = 4 * xy + np.array([pad_top+30,0])\n",
    "    # plot the keypoints in depth space\n",
    "    plt.figure(figsize = (10,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    dummy = (np.mean(c_image,2))/2\n",
    "    dummy[xy_cij[:,0],xy_cij[:,1]] = 255\n",
    "    plt.imshow(dummy)\n",
    "    plt.title('Color image, high value pixels are keypoints')\n",
    "    # plt.plot(xy_cij[:,0],xy_cij[:,1],'or')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    dummy = (dac_image%255)/(2)\n",
    "    dummy[xy_cij[:,0],xy_cij[:,1]] = 255\n",
    "    plt.imshow(dummy)\n",
    "    plt.title('Depth aligned to color image, high value pixels are keypoints')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/pre_depth_01.png\" width = 100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a wrapper for loading and composing a full 3D frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the point cloud, the keypoints fof a frame!\n",
    "\n",
    "# function which loads a single frame with keypoints\n",
    "dev = 0\n",
    "frame = 1000\n",
    "\n",
    "def load_d_and_keyp_all(frame):\n",
    "    d_world_list = [None]*4\n",
    "    keyp_list = [None]*4 \n",
    "    pkeyp_list = [None]*4 \n",
    "    score_idx_list = [None]*4\n",
    "    for dev in range(4):\n",
    "        d_world,keyp_world,pkeyp,score_idx = load_d_and_keyp(frame,dev)\n",
    "        d_world_list[dev] = d_world\n",
    "        keyp_list[dev] = keyp_world\n",
    "        score_idx_list[dev] = score_idx\n",
    "        pkeyp_list[dev] = pkeyp\n",
    "        \n",
    "    return np.concatenate(d_world_list), np.concatenate(keyp_list), np.concatenate(pkeyp_list), np.concatenate(score_idx_list)\n",
    "\n",
    "def load_full_frame(frame):\n",
    "    pos, keyp, pkeyp, keyp_idx = load_d_and_keyp_all(frame)\n",
    "    # split out, \n",
    "    pos, points_to_cam = pos[:,:3],pos[:,3]\n",
    "    # TODO could clean this up, sort of silly right now\n",
    "    \n",
    "    cut_logic = cut_by_floor_roof(pos,floor_point,floor_normal,floor_cut=0.006,roof_cut=0.15)\n",
    "    \n",
    "    pos = align_by_floor(pos,floor_point,M0)\n",
    "    keyp = align_by_floor(keyp,floor_point,M0)\n",
    "\n",
    "    cyl_logic = cut_by_cylinder(pos,r_factor= .97,showplot = False)\n",
    "    \n",
    "    # select points above the floor and inside the cylinder\n",
    "    selection_logic = cyl_logic*cut_logic\n",
    "    pos = pos[selection_logic,:]\n",
    "\n",
    "#     pos = pos[cyl_logic]\n",
    "    \n",
    "    keyp_logic = (pkeyp > .06) * cut_by_cylinder(keyp,r_factor= .99,showplot = False)\n",
    "    \n",
    "    # and the weigths as well!\n",
    "    pos_weights = points_to_cam[selection_logic]**2\n",
    "\n",
    "    # TODO!!!! CENTER EVERYTHING BY THE CENTER OF THE CYLINDER\n",
    "    \n",
    "    pos[:,:2] = pos[:,:2] - c_cylinder[np.newaxis,:]\n",
    "    keyp[:,:2] = keyp[:,:2] - c_cylinder[np.newaxis,:]\n",
    "    \n",
    "    return pos, pos_weights, keyp[keyp_logic,:], pkeyp[keyp_logic], keyp_idx[keyp_logic]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Again, check with a few plots that it looks fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrelli/anaconda2/envs/mousepose/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    }
   ],
   "source": [
    "frame = 15000+1\n",
    "pos, pos_weights, keyp, pkeyp, keyp_idx = load_full_frame(frame)\n",
    "cheap4d(pos[::3],keyp,keyp_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/pre_depth_02.png\" width = 50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheap3d(pos[::3],rgb = pos_weights[::3]/(pos_weights.max()), new=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/pre_depth_03.png\" width = 50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make functions to pack and unpack 3D data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make functions to pack and unpack data to a single string\n",
    "def pack_to_jagged(pos, pos_weights, keyp, pkeyp, keyp_idx):\n",
    "    ''' Takes the NX3, N, Mx3, M, M shapes and packs to a single float16\n",
    "    We ravel the position, ravel the keyp, stack everything and \n",
    "    - importantly - we also save M, the number of keypoints'''\n",
    "    n_keyp = keyp_idx.shape[0]\n",
    "    block = np.hstack([pos,pos_weights[:,np.newaxis]])\n",
    "    jagged_line = np.hstack((block.ravel(),keyp.ravel(),pkeyp,keyp_idx,n_keyp))\n",
    "    return jagged_line\n",
    "\n",
    "jagged_line = pack_to_jagged(pos, pos_weights, keyp, pkeyp, keyp_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_from_jagged(jagged_line):\n",
    "    ''' THE REVESER SO HERE IT UNPACKS AGAIN SO THE DATA CAN BE SAVED\n",
    "    AS A JAGGED H5PY DATASET \n",
    "    FROM OTHER: Takes the NX3, N, Mx3, M, M shapes and packs to a single float16\n",
    "    We ravel the position, ravel the keyp, stack everything and \n",
    "    - importantly - we also save M, the number of keypoints'''\n",
    "    n_keyp = int(jagged_line[-1])\n",
    "    keyp_idx2 = jagged_line[-(1+n_keyp):-1].astype('int')\n",
    "    pkeyp2 = jagged_line[-(1+2*n_keyp):-(1+n_keyp)]\n",
    "    keyp2 = jagged_line[-(1+5*n_keyp):-(1+2*n_keyp)].reshape((n_keyp,3))\n",
    "    block2 = jagged_line[:-(1+5*n_keyp)].reshape((-1,4))\n",
    "    pos2,pos_weights2 = block2[:,:3], block2[:,3]\n",
    "    return pos2, pos_weights2, keyp2, pkeyp2, keyp_idx2\n",
    "\n",
    "pos2, pos_weights2, keyp2, pkeyp2, keyp_idx2 = unpack_from_jagged(jagged_line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process all frames and dump to hdf5 file as jagged arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW we actually pre-process the data, required for saving and compressing the data\n",
    "\n",
    "# OK OK OK, now select the reference camera!\n",
    "n_frames = len(timing['reference_stamps'])\n",
    "\n",
    "# open a file for the \n",
    "with h5py.File(top_folder_0+'/pre_processed_frames.hdf5', mode='w') as hdf5_file:\n",
    "    # make the variable length dataset, go with float16 for now\n",
    "    dt = h5py.special_dtype(vlen=np.dtype('float16'))\n",
    "    hdf5_file.create_dataset('dataset', (n_frames,), dtype=dt)\n",
    "    \n",
    "    # now, loop over the frames and save them\n",
    "    for frame in tqdm_notebook(range(n_frames)):\n",
    "        # load the frame\n",
    "        pos, pos_weights, keyp, pkeyp, keyp_idx = load_full_frame(frame)\n",
    "        # pack to a single line for jagged h5py\n",
    "        jagged_line = pack_to_jagged(pos[::2], pos_weights[::2], keyp, pkeyp, keyp_idx)\n",
    "        # write to the h5py file\n",
    "        hdf5_file['dataset'][frame] = jagged_line.astype('float16')\n",
    "    print(\"Done with {} frames!\".format(n_frames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if file is good: Reload data from hdf5 file, unpack and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['dataset']>\n",
      "74962\n",
      "[0 1 1 2 2 3 0 1 1 1 2 3 0 1 1 1 3 3 0 1 1 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# now, try to load some data, to see if it is OK\n",
    "with h5py.File(top_folder_0+'/pre_processed_frames.hdf5', mode='r') as hdf5_file:\n",
    "    print(hdf5_file.keys())\n",
    "    print(len(hdf5_file['dataset']))\n",
    "    jagged_line = hdf5_file['dataset'][71950] \n",
    "    \n",
    "    pos, pos_weights, keyp, pkeyp, keyp_idx = unpack_from_jagged(jagged_line)\n",
    "    print(keyp_idx)\n",
    "    cheap4d(pos,keyp,keyp_idx)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Dump frames for a video showing the pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the hourglass model and set up architecture\n",
    "from architectures.hourglass import hg\n",
    "global best_acc\n",
    "\n",
    "model = hg(\n",
    "    num_stacks=8,\n",
    "    num_blocks=1,\n",
    "    num_classes=11,\n",
    "    num_feats=128,\n",
    "    inplanes=64,\n",
    "    init_stride=2,\n",
    ")\n",
    "    \n",
    "model = torch.nn.DataParallel(model).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights '192x320_weights/singlecore_weights_epoch_135_loss_1565.910_2019-11-22_11-14-39.pth'\n",
      "loaded!\n"
     ]
    }
   ],
   "source": [
    "# A HELPER FUNCTION WHICH SAVES THE STATE OF THE NETWORK, maybe every 10 epochs or smth?\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import string\n",
    "import random\n",
    "import shutil\n",
    "import glob\n",
    "epoch = 50\n",
    "epoch = 110\n",
    "\n",
    "# save_weights(model, 0, 1000)    \n",
    "# def load_weights(model, epoch):\n",
    "WEIGHTS_PATH = '192x320_weights/'\n",
    "\n",
    "# # the the most recent from that epoch\n",
    "# all_options = sorted( glob.glob(WEIGHTS_PATH + '/singlecore_weights_epoch_'+str(epoch)+'*' ) )\n",
    "# print(all_options)\n",
    "# weights_fpath = all_options[0]\n",
    "\n",
    "# CHOSEN\n",
    "weights_fpath = WEIGHTS_PATH + 'singlecore_weights_epoch_135_loss_1565.910_2019-11-22_11-14-39.pth'\n",
    "print(\"loading weights '{}'\".format(weights_fpath))\n",
    "model.load_state_dict( torch.load(weights_fpath) )\n",
    "model.eval()\n",
    "print('loaded!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRAP inside of a pytorch dataset\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "from c_utils.utils_hour import gaussian\n",
    "\n",
    "class ReadDataset(data.Dataset):\n",
    "    # todo add augmentation here, clean up and make faster\n",
    "    # todo remove stupid side effects etc\n",
    "    def __init__(self, dev,png_files):\n",
    "        '''Initialization'''\n",
    "        self.dev = dev\n",
    "        self.file_list = png_files[dev]\n",
    "        self.n_frames = len(self.file_list)\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.n_frames    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # returns the image in RBG\n",
    "        c_image = cv2.imread(self.file_list[index])\n",
    "        # REMEMBER TO CUT DOWN THE TOP of the revolution, such that the image is 192x320\n",
    "        # pack depth and pixels to target - OR NOT??\n",
    "        im = c_image\n",
    "        frame_height = im.shape[0]\n",
    "        frame_width = im.shape[1]\n",
    "        \n",
    "        # make the resolution correct, i.e. set the height to 192\n",
    "        pad_top = 8\n",
    "        pad_bottom = 10\n",
    "        im = im[pad_top:-pad_bottom,:,:]       \n",
    "        # return the index AND flip from rgb to bgr AND normalize to 0 to 1\n",
    "#         return index, np.moveaxis( im[:,:,[2,1,0]], 2, 0)\n",
    "        return index, np.moveaxis( im, 2, 0)\n",
    "\n",
    "    \n",
    "# # we shuffle, so that we always see different dumps\n",
    "dev = 0\n",
    "FrameLoader = data.DataLoader( ReadDataset(dev,png_files) , batch_size=12, shuffle=False, num_workers = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to pass through the network\n",
    "def im_batch_2_full_scores(im_batch,model):\n",
    "    inputs = im_batch.float().div(255.).cuda()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # compute model output\n",
    "        output = model(inputs)\n",
    "        # get the resulting scores out! Drop the affinity maps\n",
    "        scores = output[-1][:,:,:,:]\n",
    "    return scores.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Here we hardcode the x abd y limits to remove the stutter in the video, also a bit hacky\n",
    "\n",
    "def cheap4d_pretty(pos,keyp,keyp_idx,rgb = None, new=True,hard_limits = None):\n",
    "    from matplotlib import rcParams\n",
    "    rcParams['font.family'] = 'serif'\n",
    "    #   3D plot of the\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    X, Y, Z = pos[:,0],pos[:,1],pos[:,2]\n",
    "\n",
    "    #   3D plot of Sphere\n",
    "    fig = plt.figure(figsize = (5,5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(X, Y, Z, zdir='z',marker='.', s=8,c='k', alpha = .03, rasterized=False)\n",
    "#     ax.set_aspect('equal')\n",
    "    #ax.set_xlim3d(-35, 35)\n",
    "    #ax.set_ylim3d(-35,35)\n",
    "    #ax.set_zlim3d(-70,0)\n",
    "    \n",
    "    body_colors = ['dodgerblue','red','lime','orange']\n",
    "    for i,body in enumerate(keyp_idx):\n",
    "        if body == 0:\n",
    "            sz = 40\n",
    "        else:\n",
    "            sz = 40\n",
    "        ax.scatter(keyp[i,0], keyp[i,1], keyp[i,2], zdir='z', s=sz, c=body_colors[body],rasterized=False)\n",
    "    \n",
    "#     ax.set_xlabel('$x$ (mm)',fontsize=16)\n",
    "#     ax.set_ylabel('\\n$y$ (mm)',fontsize=16)\n",
    "#     zlabel = ax.set_zlabel('\\n$z$ (mm)',fontsize=16)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "    ax.set_zticklabels('')\n",
    "\n",
    "    max_range = np.array([X.max()-X.min(), Y.max()-Y.min(), Z.max()-Z.min()]).max() / 2.0\n",
    "\n",
    "    mid_x = (X.max()+X.min()) * 0.5\n",
    "    mid_y = (Y.max()+Y.min()) * 0.5\n",
    "    mid_z = (Z.max()+Z.min()) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "#     ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "    ax.set_zlim(0 , 2*max_range)\n",
    "    if hard_limits is not None:\n",
    "        mid_x,mid_y,max_range = hard_limits\n",
    "        ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "        ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "        ax.set_zlim(0 , 2*max_range)\n",
    "\n",
    "    print()\n",
    "    plt.show()\n",
    "    return ax\n",
    "plt.close('all')\n",
    "# cheap4d(pos[::9],keyp,keyp_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import peak_local_max\n",
    "\n",
    "def single_score_2_keypoints(sco):\n",
    "    xy_list = [None]*4\n",
    "    pxy_list = [None]*4\n",
    "    score_idx_list = [None]*4\n",
    "    for key in range(4):\n",
    "        xy = peak_local_max(sco[key,:,:],threshold_abs = 0.5,num_peaks = 6)\n",
    "        xy_list[key] = xy\n",
    "        pxy_list[key] = sco[key,xy[:,0],xy[:,1]]\n",
    "        # print(xy.shape)\n",
    "        score_idx_list[key] = key * np.ones_like(xy)\n",
    "\n",
    "    return np.concatenate(xy_list), np.concatenate(pxy_list), np.concatenate(score_idx_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also, we need the camera indices here, so I just add them -- little bit hacky, sorry, will fix later\n",
    "# load the point cloud, the keypoints fof a frame!\n",
    "\n",
    "def load_d_and_keyp(frame,dev):\n",
    "    # get the frame # from the master table\n",
    "    frame = timing['master_frame_table'][frame,dev]\n",
    "    # # load the frame and the keypoints\n",
    "    # d_image = np.load(d_files[dev][raw_frame])\n",
    "    c_image,d_image = load_dc_frames(frame,dev,d_files,png_files)\n",
    "    dac_image =  align_d_to_c(d_image,c_image,dev,geometry)\n",
    "    xy, pxy, score_idx = unpack_keypoints(keyp_datasets,dev,frame)\n",
    "\n",
    "    # scale the keypoints up to the color space, remember the 32 offset\n",
    "    # make the resolution correct, i.e. set the height to 192\n",
    "    # ALSO remember that there was a 30 px cut\n",
    "    pad_top = 8\n",
    "    pad_bottom = 10\n",
    "    # im = im[pad_top:-pad_bottom,:,:]\n",
    "    xy_cij = 4 * xy + np.array([pad_top+30,0])\n",
    "\n",
    "    # move the keypoints from color pixel space to depth pixel space\n",
    "    # discussion here: https://github.com/IntelRealSense/librealsense/issues/2137\n",
    "\n",
    "    #TODO take average around point!\n",
    "    xy_d = dac_image[xy_cij[:,0],xy_cij[:,1]] \n",
    "    \n",
    "    xy_d = np.zeros_like(xy[:,0])\n",
    "    for i in range(xy.shape[0]):\n",
    "#         pixels = dac_image[np.meshgrid( np.arange(-2,3) + xy_cij[i,0], np.arange(-2,3) + xy_cij[i,1])]\n",
    "        # TRY A BIGGER LOOK?\n",
    "#         square_window = np.arange(-4,5)\n",
    "        square_window = np.arange(-2,3)\n",
    "#         square_window = np.arange(0,1)\n",
    "        pixels = dac_image[np.meshgrid( square_window + xy_cij[i,0], square_window + xy_cij[i,1])]\n",
    "        # take the median of all pixels there?\n",
    "        xy_d[i] = np.nanmax( [np.median(pixels[pixels > 0].ravel()) , 0])\n",
    "        # or siply take the one closest to the camera, good for noses\n",
    "#         print([np.meshgrid( square_window + xy_cij[i,0], square_window + xy_cij[i,1])])\n",
    "#         print(pixels)\n",
    "#         print(pixels[pixels > 0].ravel())\n",
    "#         print(xy_cij)\n",
    "#         print(xy_d[i])\n",
    "#         print(dac_image.shape)\n",
    "#         xy_d[i] = np.nanmax( [np.min(pixels[pixels > 0].ravel()) , 0])\n",
    "\n",
    "    # convert the keypoints to XYZ\n",
    "    fx,fy,ppx,ppy,depth_scale,fps,frame_width,frame_height = geometry['d_cam_params'][dev]\n",
    "    fps,frame_width,frame_height = fps.astype('int'),frame_width.astype('int'),frame_height.astype('int')\n",
    "    fx_c,fy_c,ppx_c,ppy_c,_,_,_,_ =  geometry['c_cam_params'][dev]\n",
    "\n",
    "    # FIX the geometry due to downsample\n",
    "    # divide the xy because downsample\n",
    "    fx,fy,ppx,ppy = fx/2,fy/2,ppx/2,ppy/2\n",
    "    fx_c,fy_c,ppx_c,ppy_c = fx_c/2,fy_c/2,ppx_c/2,ppy_c/2\n",
    "    frame_width,frame_height = int(frame_width/2),int(frame_height/2)\n",
    "\n",
    "\n",
    "    z_c = xy_d*depth_scale # +1e-6\n",
    "\n",
    "    # and now use pinhole cam function to get the x and y\n",
    "    x_c = (xy_cij[:,1] - ppx_c) * z_c / fx_c\n",
    "    y_c = (xy_cij[:,0] - ppy_c) * z_c / fy_c    \n",
    "\n",
    "    # # and pack to a stack of positions!\n",
    "    keyp_color_space = np.vstack((x_c,y_c,z_c)).T    \n",
    "\n",
    "    # SWING THESE POSITIONS TO THE DEPTH SPACE\n",
    "    R_extr = geometry['R_extrinsics'][dev]\n",
    "    t_extr = geometry['t_extrinsics'][dev]\n",
    "    keyp_depth_space = np.einsum('ij,aj->ai',R_extr.T,(keyp_color_space - t_extr ))\n",
    "\n",
    "    # also unpack the depth points!\n",
    "    # get the expanded once more\n",
    "    pi,pj = np.where( (d_image>0) )\n",
    "\n",
    "    # pi,pj = np.where( (d>0 ) ) # simply all\n",
    "    # get the depth of the masked pixels as a raveled list\n",
    "    dij = d_image[pi,pj]\n",
    "\n",
    "    # z is easy to calculate, it's just the depth\n",
    "    z_m = dij*depth_scale # +1e-6\n",
    "    # z_m = np.clip(z_m,0.,.5)\n",
    "\n",
    "    # and now use pinhole cam function to get the x and y\n",
    "    x_m = (pj - ppx) * z_m / fx\n",
    "    y_m = (pi - ppy) * z_m / fy\n",
    "\n",
    "    d_positions = np.vstack((x_m,y_m,z_m)).T    \n",
    "    \n",
    "    points_to_cam = np.linalg.norm(d_positions,axis=1)\n",
    "\n",
    "    d_world = apply_rigid_transformation(d_positions,geometry['R_world'][dev],geometry['t_world'][dev])\n",
    "    keyp_world = apply_rigid_transformation(keyp_depth_space,geometry['R_world'][dev],geometry['t_world'][dev])    \n",
    "    \n",
    "    # add the distance as a fourth dimension to the positions\n",
    "#     d_world_weights = np.hstack([d_world,points_to_cam[:,np.newaxis]])\n",
    "    \n",
    "    # HACK for plotting, add the camera indices as well:\n",
    "    d_world_weights = np.hstack([d_world,points_to_cam[:,np.newaxis],dev*np.ones_like(points_to_cam[:,np.newaxis])])\n",
    "    \n",
    "    \n",
    "    return d_world_weights,keyp_world,pxy,score_idx\n",
    "\n",
    "def load_d_and_keyp_all(frame):\n",
    "    d_world_list = [None]*4\n",
    "    keyp_list = [None]*4 \n",
    "    pkeyp_list = [None]*4 \n",
    "    score_idx_list = [None]*4\n",
    "    for dev in range(4):\n",
    "        d_world,keyp_world,pkeyp,score_idx = load_d_and_keyp(frame,dev)\n",
    "        d_world_list[dev] = d_world\n",
    "        keyp_list[dev] = keyp_world\n",
    "        score_idx_list[dev] = score_idx\n",
    "        pkeyp_list[dev] = pkeyp\n",
    "        \n",
    "    return np.concatenate(d_world_list), np.concatenate(keyp_list), np.concatenate(pkeyp_list), np.concatenate(score_idx_list)\n",
    "\n",
    "def load_full_frame(frame):\n",
    "    pos, keyp, pkeyp, keyp_idx = load_d_and_keyp_all(frame)\n",
    "    # split out, \n",
    "    pos, points_to_cam,cam_idx = pos[:,:3],pos[:,3],pos[:,4]\n",
    "    # TODO could clean this up, sort of silly right now\n",
    "    \n",
    "    cut_logic = cut_by_floor_roof(pos,floor_point,floor_normal,floor_cut=0.006,roof_cut=0.15)\n",
    "    \n",
    "    pos = align_by_floor(pos,floor_point,M0)\n",
    "    keyp = align_by_floor(keyp,floor_point,M0)\n",
    "\n",
    "    cyl_logic = cut_by_cylinder(pos,r_factor= .96,showplot = False)\n",
    "    \n",
    "    # select points above the floor and inside the cylinder\n",
    "    selection_logic = cyl_logic*cut_logic\n",
    "    pos = pos[selection_logic,:]\n",
    "\n",
    "#     pos = pos[cyl_logic]\n",
    "    \n",
    "    keyp_logic = (pkeyp > .06) * cut_by_cylinder(keyp,r_factor= .97,showplot = False)\n",
    "    \n",
    "    # and the weigths as well!\n",
    "    pos_weights = points_to_cam[selection_logic]**2\n",
    "    cam_idx = cam_idx[selection_logic]\n",
    "    # TODO!!!! CENTER EVERYTHING BY THE CENTER OF THE CYLINDER\n",
    "    \n",
    "    pos[:,:2] = pos[:,:2] - c_cylinder[np.newaxis,:]\n",
    "    keyp[:,:2] = keyp[:,:2] - c_cylinder[np.newaxis,:]\n",
    "    \n",
    "    return pos, pos_weights, cam_idx, keyp[keyp_logic,:], pkeyp[keyp_logic], keyp_idx[keyp_logic]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from c_utils.utils_hour import convet_to_pseudo\n",
    "\n",
    "master_frame = 15000+1-200-100\n",
    "master_frame = 15000+1\n",
    "master_frame = 7000\n",
    "# az,el = 45,45\n",
    "az,el = 20,43\n",
    "az,el = 24,56\n",
    "\n",
    "video_frames = np.arange(7000-10*30,7000+20*30,10)\n",
    "# video_frames = [7000]\n",
    "for master_frame in tqdm(video_frames):\n",
    "    plt.close('all')\n",
    "\n",
    "    plt.figure(figsize=(10,5.6))\n",
    "    #dev,subcounter = 0,2\n",
    "\n",
    "    for dev,subcounter in enumerate([2,0,1,3]):\n",
    "        frame = timing['master_frame_table'][master_frame,dev]\n",
    "\n",
    "        c_image,d_image = load_dc_frames(frame,dev,d_files,png_files)\n",
    "        dac_image =  align_d_to_c(d_image,c_image,dev,geometry)\n",
    "\n",
    "        # make a version to calculate the score as well!\n",
    "        im_batch = torch.zeros(1,3,192,320)\n",
    "        pad_top = 8+30\n",
    "        pad_bottom = 10\n",
    "        im = c_image[pad_top:-pad_bottom,:,:]       \n",
    "        im_batch[0,...] = torch.from_numpy(np.moveaxis( im, 2, 0))\n",
    "        sco = im_batch_2_full_scores(im_batch,model)\n",
    "\n",
    "        xy, pxy, score_idx = single_score_2_keypoints(sco[0,:4,:,:])\n",
    "        score_idx = score_idx[:,0]\n",
    "    #         xy, pxy, score_idx = unpack_keypoints(keyp_datasets,dev,frame)\n",
    "        # scale the keypoints up to the color space, remember the 32 offset\n",
    "        # make the resolution correct, i.e. set the height to 192\n",
    "        # ALSO remember that there was a 30 px cut\n",
    "\n",
    "        xy_cij = 4 * xy + np.array([pad_top,0])\n",
    "\n",
    "        # plot the keypoints in depth space\n",
    "        plt.subplot(4,5,1+subcounter*5)\n",
    "        plt.imshow(im[:,:,[2,1,0]])\n",
    "        # plt.title('color')\n",
    "\n",
    "        plt.subplot(4,5,2+subcounter*5)\n",
    "        fx,fy,ppx,ppy,depth_scale,fps,frame_width,frame_height = geometry['d_cam_params'][dev]\n",
    "        d_image_in_m = d_image * depth_scale\n",
    "        plt.imshow(np.clip(d_image_in_m,.2,.4),cmap = 'gray')\n",
    "        # plt.imshow(np.clip(d_image_in_m,.2,.4))\n",
    "\n",
    "\n",
    "        pseudo,pseudo_net,pseudo_show = convet_to_pseudo( torch.from_numpy(sco).cuda() )\n",
    "\n",
    "        plt.subplot(4,5,3+subcounter*5)\n",
    "        plt.imshow(pseudo_net)\n",
    "\n",
    "        plt.subplot(4,5,4+subcounter*5)\n",
    "        plt.imshow(pseudo)\n",
    "\n",
    "        plt.subplot(4,5,5+subcounter*5)\n",
    "\n",
    "        dac_image_in_m = dac_image[pad_top:-pad_bottom,:] * depth_scale\n",
    "        plt.imshow(np.clip(dac_image_in_m,.2,.4),cmap='gray')\n",
    "\n",
    "        body_colors =['dodgerblue','red','lime','orange']\n",
    "        body_sizes =[10,7,7,7]\n",
    "\n",
    "        for xxyy,pp,ss in zip(xy_cij, pxy, score_idx):\n",
    "            plt.plot(xxyy[1],xxyy[0]-pad_top,'.',c=body_colors[ss],markersize = body_sizes[ss])\n",
    "\n",
    "        for i in range(4*5):\n",
    "            plt.subplot(4,5,1+i)\n",
    "            plt.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "    # left  = 0.125  # the left side of the subplots of the figure\n",
    "    # right = 0.9    # the right side of the subplots of the figure\n",
    "    # bottom = 0.1   # the bottom of the subplots of the figure\n",
    "    # top = 0.9      # the top of the subplots of the figure\n",
    "    # wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
    "    # hspace = 0.2   # the amount of height reserved for white space between subplots        \n",
    "\n",
    "    plt.subplots_adjust(wspace=.05, hspace=.01)\n",
    "\n",
    "    # plt.subplot(1,4,1)\n",
    "    # dummy = (np.mean(c_image,2))/2\n",
    "    # dummy[xy_cij[:,0],xy_cij[:,1]] = 255\n",
    "    # plt.imshow(dummy)\n",
    "    # # plt.plot(xy_cij[:,0],xy_cij[:,1],'or')\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.imshow(np.max(sco[0,...],0) )\n",
    "    # frame = 12000+100-1000\n",
    "\n",
    "    plt.savefig('videos/pipeline/example_full_pipeline_{:09d}.png'.format(master_frame), pad_inches = 0)\n",
    "\n",
    "    pos, pos_weights, cam_idx, keyp, pkeyp, keyp_idx = load_full_frame(master_frame)\n",
    "\n",
    "    ax = cheap4d_pretty(pos,keyp,keyp_idx,hard_limits = [0,0,.15])\n",
    "    az,el = -47, 6\n",
    "    ax.view_init(elev=el, azim=az)\n",
    "\n",
    "    dpi = 75\n",
    "    plt.savefig('videos/pipeline/example_3d_view_side_{:09d}.png'.format(master_frame), pad_inches = 0,dpi = dpi)\n",
    "\n",
    "    ax = cheap4d_pretty(pos,keyp,keyp_idx,hard_limits = [0,0,.15])\n",
    "    az,el = 36,70\n",
    "    ax.view_init(elev=el, azim=az)    \n",
    "    plt.savefig('videos/pipeline/example_3d_view_top_{:09d}.png'.format(master_frame), pad_inches = 0,dpi = dpi)\n",
    "#     plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/example_full_pipeline.png\" width = 100%>\n",
    "<img src=\"figs/example_3d_view_top.png\" width = 50%>\n",
    "<img src=\"figs/example_3d_view_side.png\" width = 50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the images using opencv\n",
    "# merge the videos using opencv, from here: https://gist.github.com/nkint/8576156\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "n_videos = 3\n",
    "image_folder = 'videos/pipeline'\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out_fps = 10\n",
    "width = 1105\n",
    "height = 470\n",
    "out = cv2.VideoWriter('videos/supplementary_video_pipeline.mp4', fourcc, out_fps, (width,height))\n",
    "\n",
    "# create a splash screen\n",
    "# create blank image\n",
    "img = np.zeros((int(height),int(width), 3), np.uint8)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_color = (255, 255, 255)\n",
    "h = height-.1*height\n",
    "w = (width)/2\n",
    "font_scale = 1\n",
    "thickness = 2\n",
    "text = 'Ebbesen & Froemke, 2020'\n",
    "def put_centered_text(img,text,w,h,font, font_scale, font_color, thickness):\n",
    "    # get boundary of this text\n",
    "    textsize = cv2.getTextSize(text, font, font_scale, thickness)[0]\n",
    "    cv2.putText(img, text, (int(w - textsize[0]/2),int(h) ), font, font_scale, font_color, thickness, cv2.LINE_AA)\n",
    "\n",
    "put_centered_text(img,text,w,h,font, font_scale, font_color, thickness)\n",
    "put_centered_text(img,'Supplementary video 1: Pre-processing pipeline',w,.2*height,font, font_scale, font_color, thickness)\n",
    "\n",
    "for _ in range(30):\n",
    "    cv2.imshow('pipe',img)\n",
    "    cv2.waitKey(10)\n",
    "    out.write(img)\n",
    "\n",
    "\n",
    "for frame in video_frames:\n",
    "    pipe = cv2.imread(image_folder+'/example_full_pipeline_{:09d}.png'.format(frame))\n",
    "    # crop\n",
    "    pipe = pipe[30:-60,80:-90,:]\n",
    "    h_pipe,w_pipe,_ = pipe.shape\n",
    "    \n",
    "    \n",
    "    top = cv2.imread(image_folder+'/example_3d_view_top_{:09d}.png'.format(frame))\n",
    "    # crop the top, lol\n",
    "    h_cut = 50\n",
    "    w_cut = 50\n",
    "    top = top[h_cut:-h_cut,w_cut:-w_cut,:]\n",
    "    h_top,w_top,_ = top.shape\n",
    "    \n",
    "    # make the frame\n",
    "    im = np.zeros((h_pipe,w_pipe+w_top,3),dtype='uint8')\n",
    "    \n",
    "    # add the pipe\n",
    "    im[:,:w_pipe,:] = pipe\n",
    "    \n",
    "    # add the top view\n",
    "    im[:h_top,w_pipe:(w_pipe+w_top),:] = top\n",
    "\n",
    "    # and add the side view\n",
    "    side = cv2.imread(image_folder+'/example_3d_view_side_{:09d}.png'.format(frame))\n",
    "    h_cut = 86\n",
    "    w_cut = 50\n",
    "    side = side[h_cut:-h_cut,w_cut:-w_cut,:]\n",
    "    h_side,w_side,_ = side.shape\n",
    "\n",
    "    im[(h_pipe-h_side):,w_pipe:(w_pipe+w_top),:] = side\n",
    "    \n",
    "    \n",
    "    # annotate\n",
    "    font_scale = .5\n",
    "    thickness = 1\n",
    "    font_color = (0,0,0)\n",
    "    # these centerings are kind of approximate \n",
    "    # go from ~ 45 px to ~ 673 pixels\n",
    "    spacing = (673-45)/4\n",
    "    # firs im is ~ 45-196 px\n",
    "    start_c = (196-45)/2 + 45\n",
    "    \n",
    "    put_centered_text(im,'RGB video',start_c,0.05*height,font, font_scale, font_color, thickness)\n",
    "    put_centered_text(im,'Depth video',start_c+spacing,0.05*height,font, font_scale, font_color, thickness)\n",
    "    put_centered_text(im,'Affinity fields',start_c+2*spacing,0.05*height,font, font_scale, font_color, thickness)\n",
    "    put_centered_text(im,'Keypoints',start_c+3*spacing,0.05*height,font, font_scale, font_color, thickness)\n",
    "    put_centered_text(im,'Depth aligned to RGB',start_c+4*spacing,0.05*height,font, font_scale, font_color, thickness)\n",
    "    \n",
    "    \n",
    "    put_centered_text(im,'Pre-processed data',972,0.05*height,font, font_scale, font_color, thickness)\n",
    "    \n",
    "    \n",
    "    text_label = np.zeros((26,87,3),dtype='uint8')+255\n",
    "    put_centered_text(text_label,'Cam 0',87/2,16,font, font_scale, font_color, thickness)\n",
    "    text_label = np.rot90(text_label, k=1, axes=(0, 1))\n",
    "    \n",
    "    h_text,w_text, _ = text_label.shape\n",
    "    \n",
    "    c_down = int(48)-2\n",
    "    c_shift = int( (156-48) )\n",
    "    h_shift = 10\n",
    "    im[(c_down):(c_down+h_text),h_shift:(h_shift+w_text),:] = text_label\n",
    "    \n",
    "    text_label = np.zeros((26,87,3),dtype='uint8')+255\n",
    "    put_centered_text(text_label,'Cam 1',87/2,16,font, font_scale, font_color, thickness)\n",
    "    text_label = np.rot90(text_label, k=1, axes=(0, 1))\n",
    "    im[(c_down+c_shift):(c_down+c_shift+h_text),h_shift:(h_shift+w_text),:] = text_label\n",
    "    \n",
    "    text_label = np.zeros((26,87,3),dtype='uint8')+255\n",
    "    put_centered_text(text_label,'Cam 2',87/2,16,font, font_scale, font_color, thickness)\n",
    "    text_label = np.rot90(text_label, k=1, axes=(0, 1))\n",
    "    im[(c_down+2*c_shift):(c_down+2*c_shift+h_text),h_shift:(h_shift+w_text),:] = text_label\n",
    "    \n",
    "    text_label = np.zeros((26,87,3),dtype='uint8')+255\n",
    "    put_centered_text(text_label,'Cam 3',87/2,16,font, font_scale, font_color, thickness)\n",
    "    text_label = np.rot90(text_label, k=1, axes=(0, 1))\n",
    "    im[(c_down+3*c_shift):(c_down+3*c_shift+h_text),h_shift:(h_shift+w_text),:] = text_label\n",
    "\n",
    "    \n",
    "    \n",
    "    #48 135 156\n",
    "    \n",
    "#     cv2.imshow('pipe2',text_label)\n",
    "    cv2.imshow('pipe',im)\n",
    "    out.write(im)\n",
    "\n",
    "    cv2.waitKey(50)\n",
    "    \n",
    "    \n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Make a plot to show merging of four clouds, for the manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chrelli/anaconda2/envs/mousepose/lib/python3.6/site-packages/ipykernel_launcher.py:34: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "from c_utils.utils_hour import convet_to_pseudo\n",
    "\n",
    "# Say, \"the default sans-serif font is COMIC SANS\"\n",
    "matplotlib.rcParams['font.sans-serif'] = \"Liberation Sans\"\n",
    "# Then, \"ALWAYS use sans-serif fonts\"\n",
    "matplotlib.rcParams['font.family'] = \"sans-serif\"\n",
    "\n",
    "matplotlib.rc('font', family='sans-serif') \n",
    "matplotlib.rc('text', usetex='false') \n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "\n",
    "from palettable.cmocean.sequential import Algae_6\n",
    "cmpl=Algae_6.mpl_colors\n",
    "\n",
    "\n",
    "frame = 12000+100-1000\n",
    "elev,azim = 40,-104\n",
    "elev,azim = 28,-119\n",
    "\n",
    "\n",
    "pos, pos_weights, cam_idx, keyp, pkeyp, keyp_idx = load_full_frame(frame)\n",
    "\n",
    "# def cheap3d(positions,rgb = None, new=True):\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "positions = pos\n",
    "\n",
    "X, Y, Z = positions[:,0],positions[:,1],positions[:,2]\n",
    "\n",
    "#   3D plot of Sphere\n",
    "fig = plt.figure(figsize = (7,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for dev in range(4):\n",
    "    logi = cam_idx == dev\n",
    "    ax.scatter(X[logi], Y[logi], Z[logi], zdir='z',c=cmpl[dev+1], s=1, rasterized=False)\n",
    "\n",
    "max_range = np.array([X.max()-X.min(), Y.max()-Y.min(), Z.max()-Z.min()]).max() / 2.0\n",
    "\n",
    "mid_x = (X.max()+X.min()) * 0.5\n",
    "mid_y = (Y.max()+Y.min()) * 0.5\n",
    "mid_z = (Z.max()+Z.min()) * 0.5\n",
    "ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "# ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "ax.set_zlim(0, 2* max_range)\n",
    "\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "\n",
    "ax.view_init(elev,azim)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/different_clouds.png\" width = 50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
